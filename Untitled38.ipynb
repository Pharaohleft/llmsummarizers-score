{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WemtlAUxGrlR",
        "outputId": "506b21ea-5ce3-49d0-f689-59b27430463d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m83.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m94.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install streamlit  pyngrok -q\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create main.py\n",
        "main_code = \"\"\"\n",
        "import streamlit as st\n",
        "from load_models import get_real_summaries\n",
        "\n",
        "\n",
        "st.set_page_config(page_title=\"LLM Summarizer Comparator\", layout=\"wide\")\n",
        "\n",
        "st.title(\"🔍 LLM Summarizer Comparator\")\n",
        "st.markdown(\"Compare summarization outputs from GPT-3.5, BART, and T5 on the same input text.\")\n",
        "\n",
        "user_input = st.text_area(\"Enter text to summarize\", height=200)\n",
        "\n",
        "if st.button(\"Generate Summaries\"):\n",
        "    if user_input.strip() == \"\":\n",
        "        st.warning(\"Please enter some text.\")\n",
        "    else:\n",
        "        summaries = get_real_summaries(user_input)\n",
        "\n",
        "        col1, col2, col3 = st.columns(3)\n",
        "        with col1:\n",
        "            st.subheader(\"🧠 GPT-3.5 (placeholder)\")\n",
        "            st.write(summaries['gpt'])\n",
        "\n",
        "        with col2:\n",
        "            st.subheader(\"📚 BART\")\n",
        "            st.write(summaries['bart'])\n",
        "            st.caption(f\"Length: {summaries['bart_metrics']['length']} words | ROUGE-L: {summaries['bart_metrics']['rougeL']}\")\n",
        "\n",
        "        with col3:\n",
        "            st.subheader(\"📘 T5\")\n",
        "            st.write(summaries['t5'])\n",
        "            st.caption(f\"Length: {summaries['t5_metrics']['length']} words | ROUGE-L: {summaries['t5_metrics']['rougeL']}\")\n",
        "\"\"\"\n",
        "\n",
        "with open(\"main.py\", \"w\") as f:\n",
        "    f.write(main_code)\n",
        "\n",
        "# Create load_models.py\n",
        "model_code = \"\"\"\n",
        "from transformers import pipeline\n",
        "from rouge_score import rouge_scorer\n",
        "\n",
        "\n",
        "bart_summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
        "t5_summarizer = pipeline(\"summarization\", model=\"t5-small\")\n",
        "\n",
        "def get_real_summaries(text):\n",
        "    bart_summary = bart_summarizer(text, max_length=100, min_length=30, do_sample=False)[0]['summary_text']\n",
        "    t5_summary = t5_summarizer(\"summarize: \" + text, max_length=100, min_length=30, do_sample=False)[0]['summary_text']\n",
        "\n",
        "    scorer = rouge_scorer.RougeScorer(['rougeL'], use_stemmer=True)\n",
        "    rouge_bart = scorer.score(text, bart_summary)['rougeL'].fmeasure\n",
        "    rouge_t5 = scorer.score(text, t5_summary)['rougeL'].fmeasure\n",
        "\n",
        "    return {\n",
        "        \"gpt\": \"🧠 GPT-3.5 not available in this version — coming soon via OpenAI API.\",\n",
        "        \"bart\": bart_summary,\n",
        "        \"t5\": t5_summary,\n",
        "        \"bart_metrics\": {\n",
        "            \"rougeL\": round(rouge_bart, 3),\n",
        "            \"length\": len(bart_summary.split())\n",
        "        },\n",
        "        \"t5_metrics\": {\n",
        "            \"rougeL\": round(rouge_t5, 3),\n",
        "            \"length\": len(t5_summary.split())\n",
        "        }\n",
        "    }\n",
        "\"\"\"\n",
        "\n",
        "with open(\"load_models.py\", \"w\") as f:\n",
        "    f.write(model_code)\n"
      ],
      "metadata": {
        "id": "F7CdaejGIHkB"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "import threading\n",
        "import time\n",
        "import os\n",
        "\n",
        "# Kill old tunnels\n",
        "ngrok.kill()\n",
        "\n",
        "# Launch Streamlit in background\n",
        "def run_app():\n",
        "    os.system(\"streamlit run main.py\")\n",
        "\n",
        "thread = threading.Thread(target=run_app)\n",
        "thread.start()\n",
        "\n",
        "# Wait for it to start\n",
        "time.sleep(5)\n",
        "\n",
        "# Create ngrok tunnel\n",
        "public_url = ngrok.connect(8501)\n",
        "print(\"🔗 Your app is live at:\", public_url)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-CeanIoYNrSj",
        "outputId": "e0111302-602b-4dbf-cbdd-9caf7edbde04"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔗 Your app is live at: NgrokTunnel: \"https://7eddbc4dd1b0.ngrok-free.app\" -> \"http://localhost:8501\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rouge-score\n"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GOZrrbuEWSHv",
        "outputId": "0b05433f-ab09-49d6-805b-d97eb195941a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rouge-score\n",
            "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from rouge-score) (1.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (from rouge-score) (3.9.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from rouge-score) (2.0.2)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from rouge-score) (1.17.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk->rouge-score) (8.2.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk->rouge-score) (1.5.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk->rouge-score) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk->rouge-score) (4.67.1)\n",
            "Building wheels for collected packages: rouge-score\n",
            "  Building wheel for rouge-score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24934 sha256=0a9e8739d78e44b3f745927cde372c999b1a1e9ca29d64f16f7384661d531d0b\n",
            "  Stored in directory: /root/.cache/pip/wheels/1e/19/43/8a442dc83660ca25e163e1bd1f89919284ab0d0c1475475148\n",
            "Successfully built rouge-score\n",
            "Installing collected packages: rouge-score\n",
            "Successfully installed rouge-score-0.1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ngrok config add-authtoken 30fGcyYfVah1Nmu6c7OOMGdtyb0_2GVPzRmg8EpMwub8potQX"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k0U9sGqAOqgP",
        "outputId": "99ce2708-f6ad-41ae-f747-76de3a64141f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "vuWWX_NxGzSf",
        "outputId": "e582552d-9f40-457f-e892-b31cecf1c3d1"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.54.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.34.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.4)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.14.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.7.14)\n"
          ]
        }
      ]
    }
  ]
}